{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "bert_livedoor.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "mount_file_id": "1uzF7OcShqDJ0SodBc_SoU0RWtUWrfBJE",
      "authorship_tag": "ABX9TyP8a5+Yf/OkRBqoZQOi1c2S"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MsAbHBeCF-Ef",
        "outputId": "fe634598-2b96-4157-9f2e-320d10654d55"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers==4.5.0 in /usr/local/lib/python3.7/dist-packages (4.5.0)\n",
            "Requirement already satisfied: fugashi==1.1.0 in /usr/local/lib/python3.7/dist-packages (1.1.0)\n",
            "Requirement already satisfied: ipadic==1.0.0 in /usr/local/lib/python3.7/dist-packages (1.0.0)\n",
            "Requirement already satisfied: unidic_lite==1.0.8 in /usr/local/lib/python3.7/dist-packages (1.0.8)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==4.5.0) (3.7.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==4.5.0) (4.64.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==4.5.0) (2.23.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers==4.5.0) (4.12.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.5.0) (2022.6.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.5.0) (1.21.6)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers==4.5.0) (0.0.53)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers==4.5.0) (0.10.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==4.5.0) (21.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers==4.5.0) (3.8.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers==4.5.0) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers==4.5.0) (3.0.9)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.5.0) (2022.6.15)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.5.0) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.5.0) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.5.0) (3.0.4)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.5.0) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.5.0) (1.1.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.5.0) (1.15.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers==4.5.0 fugashi==1.1.0 ipadic==1.0.0 unidic_lite==1.0.8"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import AutoModel, AutoTokenizer, BertJapaneseTokenizer, BertModel\n",
        "from torch import cuda\n",
        "import sklearn.metrics as skm\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch.nn.functional as F\n",
        "from transformers import logging\n"
      ],
      "metadata": {
        "id": "pnCaB1WEG0dr"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ymzUn6EyH7ul",
        "outputId": "dda408a6-a2d2-42ed-ed5b-897c2591a6d2"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 8\n",
        "hidden_size = 768\n",
        "max_len = 512\n",
        "drop_out_rate = 0.3"
      ],
      "metadata": {
        "id": "s0DTlUuXaQk0"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"./drive/MyDrive/Colab_Notebooks/data/livedoor_text.csv\")\n",
        "print(df.shape)\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 355
        },
        "id": "jPzhLL26GLCB",
        "outputId": "2287dc77-767a-4fee-ba71-471863e217bc"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(7367, 2)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                text  category\n",
              "0  27日に生放送された日本テレビ「バンクーバー2010」には、女子フィギュアスケートで銀メダル...         7\n",
              "1  「腐女子」という言葉をご存知でしょうか。\\nいわゆる漫画やアニメキャラなどの男性同士の恋愛（...         0\n",
              "2  展示会イベント恒例のおねいさん写真のコーナーでございます \\n\\n国内最大級の携帯電話や無線...         6\n",
              "3  芸能界を引退した島田紳助さんが、今月２８日に公開される映画「犬の首輪とコロッケと」に声だけ出...         2\n",
              "4  お花に包まれた洋館で、イケメン執事に囲まれながら、ゆったりと過ごす午後のひととき……。女の子...         5"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3e601b0d-1293-4fcb-89bd-c3d46df76320\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>27日に生放送された日本テレビ「バンクーバー2010」には、女子フィギュアスケートで銀メダル...</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>「腐女子」という言葉をご存知でしょうか。\\nいわゆる漫画やアニメキャラなどの男性同士の恋愛（...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>展示会イベント恒例のおねいさん写真のコーナーでございます \\n\\n国内最大級の携帯電話や無線...</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>芸能界を引退した島田紳助さんが、今月２８日に公開される映画「犬の首輪とコロッケと」に声だけ出...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>お花に包まれた洋館で、イケメン執事に囲まれながら、ゆったりと過ごす午後のひととき……。女の子...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3e601b0d-1293-4fcb-89bd-c3d46df76320')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-3e601b0d-1293-4fcb-89bd-c3d46df76320 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-3e601b0d-1293-4fcb-89bd-c3d46df76320');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# データセットの作成"
      ],
      "metadata": {
        "id": "Tfm6tn61oW0r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CreateDataset(Dataset):\n",
        "  def __init__(self, X, y, tokenizer0, tokenizer1, tokenizer2, tokenizer3, max_len):\n",
        "    self.X = X\n",
        "    self.y = y\n",
        "    self.tokenizers = [tokenizer0, tokenizer1, tokenizer2, tokenizer3]\n",
        "    self.max_len = max_len\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.y)\n",
        "\n",
        "  def encode(self, tokenizer, text):\n",
        "      inputs = tokenizer.encode_plus(\n",
        "          text,\n",
        "          add_special_tokens=True,\n",
        "          max_length=self.max_len,\n",
        "          padding = 'max_length',\n",
        "          truncation = True\n",
        "      )\n",
        "      return inputs\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    text = self.X[index]\n",
        "    label = self.y[index]\n",
        "    ids = []\n",
        "    mask = []\n",
        "\n",
        "    for tokenizer in self.tokenizers:\n",
        "      inputs = self.encode(tokenizer=tokenizer, text=text)\n",
        "      ids.append(torch.LongTensor(inputs['input_ids']))\n",
        "      mask.append(torch.LongTensor(inputs['attention_mask']))\n",
        "\n",
        "    return {\n",
        "      'ids': ids,\n",
        "      'mask': mask,\n",
        "      'label': label,\n",
        "      'text':text,\n",
        "    }"
      ],
      "metadata": {
        "id": "B7aXkzLgG9za"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer0 = BertJapaneseTokenizer.from_pretrained(\"cl-tohoku/bert-base-japanese-whole-word-masking\")\n",
        "tokenizer1 = BertJapaneseTokenizer.from_pretrained(\"cl-tohoku/bert-base-japanese-char-whole-word-masking\")\n",
        "tokenizer2 = BertJapaneseTokenizer.from_pretrained(\"cl-tohoku/bert-base-japanese-char-v2\")\n",
        "tokenizer3 = BertJapaneseTokenizer.from_pretrained(\"cl-tohoku/bert-base-japanese-v2\")"
      ],
      "metadata": {
        "id": "bdoMudggG_T8"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = df[\"text\"].values\n",
        "y = df[\"category\"].values"
      ],
      "metadata": {
        "id": "X2yZh73HG_YC"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_eval, X_test, y_train_eval, y_test = train_test_split(X, y, train_size=0.8)\n",
        "\n",
        "X_train, X_eval, y_train, y_eval = train_test_split(X_train_eval, y_train_eval, train_size=0.75)\n",
        "\n",
        "print(len(X_train))\n",
        "print(len(X_eval))\n",
        "print(len(X_test))\n",
        "\n",
        "print(len(y_train))\n",
        "print(len(y_eval))\n",
        "print(len(y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KuZghJ37RwyC",
        "outputId": "6b9fc622-7221-4ca9-b795-b24fa9256c54"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4419\n",
            "1474\n",
            "1474\n",
            "4419\n",
            "1474\n",
            "1474\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_train = CreateDataset(X_train, y_train, tokenizer0, tokenizer1, tokenizer2, tokenizer3, max_len=max_len)\n",
        "dataset_eval = CreateDataset(X_eval, y_eval, tokenizer0, tokenizer1, tokenizer2, tokenizer3, max_len=max_len)\n",
        "dataset_test = CreateDataset(X_test, y_test, tokenizer0, tokenizer1, tokenizer2, tokenizer3, max_len=max_len)\n",
        "\n",
        "print(dataset_train.__len__())\n",
        "print(dataset_eval.__len__())\n",
        "print(dataset_test.__len__())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F5PTf6oiG_bd",
        "outputId": "ba78dce2-731a-435f-bf0f-e5a3c5bbcad5"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4419\n",
            "1474\n",
            "1474\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(dataset_train[0][\"ids\"])"
      ],
      "metadata": {
        "id": "pVD_X9ipXi6m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "05c7cc0d-bd68-429f-9b88-b5162349c24d"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# データローダの作成"
      ],
      "metadata": {
        "id": "x9_FUL53oTdW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataloader_train = DataLoader(dataset_train, batch_size=batch_size, shuffle=True, pin_memory=True)\n",
        "dataloader_eval = DataLoader(dataset_eval, batch_size=batch_size, shuffle=False, pin_memory=True)\n",
        "dataloader_test = DataLoader(dataset_test, batch_size=batch_size, shuffle=False, pin_memory=True)\n",
        "\n",
        "# 辞書オブジェクトにまとめる\n",
        "dataloaders_dict = {\"train\": dataloader_train, \"val\": dataloader_eval}"
      ],
      "metadata": {
        "id": "BJUfrG01WT-U"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tmp = next(iter(dataloader_train))\n",
        "print(tmp[\"ids\"][0].size())\n",
        "print(tmp[\"label\"])\n",
        "print(len(tmp[\"ids\"][0]))\n",
        "print(len(tmp[\"ids\"][1]))\n",
        "print(len(tmp[\"ids\"][2]))\n",
        "print(len(tmp[\"ids\"][3]))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HrJDt5u-YTlI",
        "outputId": "24a4121b-4cb0-4d45-aa84-692e0634803f"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([8, 512])\n",
            "tensor([6, 4, 7, 1, 6, 2, 6, 3])\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# BERTモデル"
      ],
      "metadata": {
        "id": "CZPTyZ5IoQka"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model0 = BertModel.from_pretrained(\"cl-tohoku/bert-base-japanese-whole-word-masking\", output_attentions=True, output_hidden_states=True)\n",
        "model1 = BertModel.from_pretrained(\"cl-tohoku/bert-base-japanese-char-whole-word-masking\", output_attentions=True, output_hidden_states=True)\n",
        "model2 = BertModel.from_pretrained(\"cl-tohoku/bert-base-japanese-char-v2\", output_attentions=True, output_hidden_states=True)\n",
        "model3 = BertModel.from_pretrained(\"cl-tohoku/bert-base-japanese-v2\", output_attentions=True, output_hidden_states=True)"
      ],
      "metadata": {
        "id": "sJX70XFWG_ee"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import nn\n",
        "\n",
        "class MultiBertModel(nn.Module):\n",
        "    '''\n",
        "    BERTモデルにLivedoorニュースの9クラスを判定する部分をつなげたモデル\n",
        "    '''\n",
        "\n",
        "    def __init__(self):\n",
        "        super(MultiBertModel, self).__init__()\n",
        "\n",
        "        # 日本語学習済みのBERTモデル\n",
        "        # self.berts = [model0, model1, model2, model3] \n",
        "        self.bert0 = model0\n",
        "        self.bert1 = model1\n",
        "        self.bert2 = model2\n",
        "        self.bert3 = model3 \n",
        "\n",
        "        # DropOut\n",
        "        self.drop = nn.Dropout(drop_out_rate)\n",
        "\n",
        "        # BiLSTM\n",
        "        self.lstm = torch.nn.LSTM(hidden_size*4, hidden_size, batch_first=True, bidirectional=True)\n",
        "\n",
        "        # headにクラス予測を追加\n",
        "        # 入力はBERTの出力特徴量の次元768、出力は9クラス\n",
        "        self.cls = nn.Linear(in_features=hidden_size*2, out_features=9)\n",
        "\n",
        "        # 重み初期化処理\n",
        "        nn.init.normal_(self.cls.weight, std=0.02)\n",
        "        nn.init.normal_(self.cls.bias, 0)\n",
        "\n",
        "        # カウント\n",
        "        self.count = 0\n",
        "\n",
        "\n",
        "    def forward(self, input_ids, attention_show_flg:bool):\n",
        "        '''\n",
        "        input_ids： [batch_size, sequence_length]の文章の単語IDの羅列\n",
        "        '''\n",
        "\n",
        "        # BERTの基本モデル部分の順伝搬\n",
        "        # 順伝搬させる\n",
        "        attentions = []\n",
        "        # BERTの順伝搬\n",
        "        # print(f\"ids_{i} is cuda: {input_ids[i].is_cuda}\")\n",
        "        output0 = self.bert0(input_ids[0])\n",
        "        output1 = self.bert1(input_ids[1])\n",
        "        output2 = self.bert2(input_ids[2])\n",
        "        output3 = self.bert3(input_ids[3])\n",
        "        # 最終4層の隠れ層の状態を取得\n",
        "        sequence_output0 = torch.cat([output0[\"hidden_states\"][-1*i][:,0] for i in range(1, 5)], dim=1)\n",
        "        sequence_output1 = torch.cat([output1[\"hidden_states\"][-1*i][:,0] for i in range(1, 5)], dim=1)\n",
        "        sequence_output2 = torch.cat([output2[\"hidden_states\"][-1*i][:,0] for i in range(1, 5)], dim=1)\n",
        "        sequence_output3 = torch.cat([output3[\"hidden_states\"][-1*i][:,0] for i in range(1, 5)], dim=1) \n",
        "\n",
        "        # Attentionの最終層を保持\n",
        "        attentions.append(output0.attentions[-1])\n",
        "        attentions.append(output1.attentions[-1])\n",
        "        attentions.append(output2.attentions[-1])\n",
        "        attentions.append(output3.attentions[-1])\n",
        "        \n",
        "\n",
        "        vec = torch.stack((sequence_output0, sequence_output1, sequence_output2, sequence_output3), 1)\n",
        "\n",
        "        # BiLSTM\n",
        "        _, lstmout= self.lstm(vec, None)\n",
        "        bilstm_out = torch.cat([lstmout[0][0], lstmout[0][1]], dim=1)\n",
        "\n",
        "        # 全結合層\n",
        "        output = self.cls(self.drop(bilstm_out))  \n",
        "\n",
        "        self.count += 1\n",
        "\n",
        "        if attention_show_flg:\n",
        "          return output, attentions\n",
        "        else:\n",
        "          return output\n"
      ],
      "metadata": {
        "id": "kt7Ox3ISQhyQ"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# モデル構築\n",
        "net = MultiBertModel()\n",
        "\n",
        "# 訓練モードに設定\n",
        "net.train()\n",
        "\n",
        "print('ネットワーク設定完了')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oYAN0RMZRZ-F",
        "outputId": "34bf815c-e2f3-4f57-e1fd-b55488b80a3d"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ネットワーク設定完了\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 勾配計算を最後のBertLayerモジュールと追加した分類アダプターのみ実行\n",
        "\n",
        "# 1. まず全部を、勾配計算Falseにしてしまう\n",
        "for param in net.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# 2. 各モジュールの一部の層を勾配計算ありに変更\n",
        "for i in range(1, 5):\n",
        "  for param in net.bert0.encoder.layer[-1*i].parameters():\n",
        "      param.requires_grad = True\n",
        "  for param in net.bert1.encoder.layer[-1*i].parameters():\n",
        "      param.requires_grad = True\n",
        "  for param in net.bert2.encoder.layer[-1*i].parameters():\n",
        "      param.requires_grad = True\n",
        "  for param in net.bert3.encoder.layer[-1*i].parameters():\n",
        "      param.requires_grad = True\n",
        "  \n",
        "for param in net.lstm.parameters():\n",
        "      param.requires_grad =True\n",
        "\n",
        "# 3. 識別器を勾配計算ありに変更\n",
        "for param in net.cls.parameters():\n",
        "    param.requires_grad = True"
      ],
      "metadata": {
        "id": "yESzArCNRaee"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 最適化に渡すパラメータ\n",
        "model_params = [{'params': net.bert0.encoder.layer[-1*i].parameters(), 'lr': 5e-5} for i in range(1,5)]\n",
        "model_params.extend([{'params': net.bert1.encoder.layer[-1*i].parameters(), 'lr': 5e-5} for i in range(1,5)])\n",
        "model_params.extend([{'params': net.bert2.encoder.layer[-1*i].parameters(), 'lr': 5e-5} for i in range(1,5)])\n",
        "model_params.extend([{'params': net.bert3.encoder.layer[-1*i].parameters(), 'lr': 5e-5} for i in range(1,5)])\n",
        "\n",
        "lstm_params = [{'params':net.lstm.parameters(),'lr':5e-5}]\n",
        "model_params.extend(lstm_params)\n",
        "\n",
        "linear_params = [{'params': net.cls.parameters(), 'lr': 1e-4}]\n",
        "model_params.extend(linear_params)"
      ],
      "metadata": {
        "id": "WeOa5faFQJO2"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 最適化手法の設定\n",
        "import torch.optim as optim\n",
        "optimizer = optim.Adam(model_params)\n",
        "\n",
        "# 損失関数の設定\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "# nn.LogSoftmax()を計算してからnn.NLLLoss(negative log likelihood loss)を計算"
      ],
      "metadata": {
        "id": "Ze8n1lpURaoD"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 学習・検証"
      ],
      "metadata": {
        "id": "g83K9OAfoN1J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# モデルを学習させる関数を作成\n",
        "# torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
        "\n",
        "def train_model(net, dataloaders_dict, criterion, optimizer, num_epochs):\n",
        "\n",
        "    # GPUが使えるかを確認\n",
        "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(\"使用デバイス：\", device)\n",
        "    print('-----start-------')\n",
        "\n",
        "    # ネットワークをGPUへ\n",
        "    net.to(device)\n",
        "    print(next(net.parameters()).is_cuda)\n",
        "\n",
        "    # ネットワークがある程度固定であれば、高速化させる\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "\n",
        "    # ミニバッチのサイズ\n",
        "    batch_size = dataloaders_dict[\"train\"].batch_size\n",
        "\n",
        "    # epochのループ\n",
        "    for epoch in range(num_epochs):\n",
        "        # epochごとの訓練と検証のループ\n",
        "        for phase in ['train', 'val']:\n",
        "            if phase == 'train':\n",
        "                net.train()  # モデルを訓練モードに\n",
        "            else:\n",
        "                net.eval()   # モデルを検証モードに\n",
        "\n",
        "            epoch_loss = 0.0  # epochの損失和\n",
        "            epoch_corrects = 0  # epochの正解数\n",
        "            iteration = 1\n",
        "\n",
        "            # データローダーからミニバッチを取り出すループ\n",
        "            for batch in (dataloaders_dict[phase]):\n",
        "                # batchはTextとLableの辞書型変数\n",
        "\n",
        "                # GPUが使えるならGPUにデータを送る\n",
        "                ids_for_multi_bert = []\n",
        "                for i in range(4):\n",
        "                  ids_for_multi_bert.append(batch[\"ids\"][i].to(device, non_blocking=True))\n",
        "                \n",
        "                labels = batch[\"label\"].to(device)  # ラベル\n",
        "\n",
        "                # optimizerを初期化\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # 順伝搬（forward）計算\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "\n",
        "                    outputs = net(ids_for_multi_bert, attention_show_flg=False)\n",
        "\n",
        "                    loss = criterion(outputs, labels)  # 損失を計算\n",
        "\n",
        "                    _, preds = torch.max(outputs, 1)  # ラベルを予測\n",
        "\n",
        "                    # 訓練時はバックプロパゲーション\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                        if (iteration % 10 == 0):  # 10iterに1度、lossを表示\n",
        "                            acc = (torch.sum(preds == labels.data)\n",
        "                                   ).double()/batch_size\n",
        "                            print('イテレーション {} || Loss: {:.4f} || 10iter. || 本イテレーションの正解率：{}'.format(\n",
        "                                iteration, loss.item(),  acc))\n",
        "\n",
        "                    iteration += 1\n",
        "\n",
        "                    # 損失と正解数の合計を更新\n",
        "                    epoch_loss += loss.item() * batch_size\n",
        "                    epoch_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "            # epochごとのlossと正解率\n",
        "            epoch_loss = epoch_loss / len(dataloaders_dict[phase].dataset)\n",
        "            epoch_acc = epoch_corrects.double(\n",
        "            ) / len(dataloaders_dict[phase].dataset)\n",
        "\n",
        "            print('Epoch {}/{} | {:^5} |  Loss: {:.4f} Acc: {:.4f}'.format(epoch+1, num_epochs,\n",
        "                                                                           phase, epoch_loss, epoch_acc))\n",
        "\n",
        "    return net"
      ],
      "metadata": {
        "id": "dPcjornYRawV"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 学習・検証を実行する。1epochに2分ほどかかります\n",
        "# num_epochs = 4\n",
        "# net_trained = train_model(net, dataloaders_dict,\n",
        "#                           criterion, optimizer, num_epochs=num_epochs)\n",
        "#\n",
        "# モデル保存\n",
        "# save_path = \"./drive/MyDrive/Colab_Notebooks/model/bert_fine_tuning_livedoor.pth\"\n",
        "# torch.save(net_trained.state_dict(), save_path)"
      ],
      "metadata": {
        "id": "HvIKi67TRa2w"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "veu4XXjrylPh"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# モデル読み込み\n",
        "net_trained = MultiBertModel()\n",
        "\n",
        "save_path = \"./drive/MyDrive/Colab_Notebooks/model/bert_fine_tuning_livedoor.pth\"\n",
        "net_trained.load_state_dict(torch.load(save_path))"
      ],
      "metadata": {
        "id": "5ILvvUrcGVKh",
        "outputId": "e9816b68-f663-4ab3-9583-bc9e973692b5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "next(net_trained.parameters()).size()"
      ],
      "metadata": {
        "id": "jiwWwALmFAdo",
        "outputId": "8a27c914-2842-4d79-c68a-b63e9f73e2c2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([32000, 768])"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "# テストデータでの正解率を求める\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "net_trained.eval()   # モデルを検証モードに\n",
        "net_trained.to(device)  # GPUが使えるならGPUへ送る\n",
        "\n",
        "# epochの正解数を記録する変数\n",
        "epoch_corrects = 0\n",
        "\n",
        "# モデル評価用データ\n",
        "labels_all = []\n",
        "preds_all = []\n",
        "\n",
        "for batch in tqdm(dataloader_test):  # testデータのDataLoader\n",
        "    # batchはTextとLableの辞書オブジェクト\n",
        "    # GPUが使えるならGPUにデータを送る\n",
        "    ids_for_multi_bert = []\n",
        "    for i in range(4):\n",
        "      ids_for_multi_bert.append(batch[\"ids\"][i].to(device, non_blocking=True))\n",
        "    labels = batch[\"label\"].to(device)  # ラベル\n",
        "\n",
        "    # 順伝搬（forward）計算\n",
        "    with torch.set_grad_enabled(False):\n",
        "\n",
        "        # BertForLivedoorに入力\n",
        "        outputs = net_trained(ids_for_multi_bert, attention_show_flg=False)\n",
        "\n",
        "        loss = criterion(outputs, labels)  # 損失を計算\n",
        "        _, preds = torch.max(outputs, 1)  # ラベルを予測\n",
        "        epoch_corrects += torch.sum(preds == labels.data)  # 正解数の合計を更新\n",
        "\n",
        "        # f1計算用\n",
        "        labels_all.extend(batch[\"label\"].to('cpu').detach().numpy())\n",
        "        preds_all.extend(preds.to('cpu').detach().numpy())\n",
        "\n",
        "# 正解率\n",
        "epoch_acc = epoch_corrects.double() / len(dataloader_test.dataset)\n",
        "\n",
        "print('テストデータ{}個での正解率：{:.4f}'.format(len(dataloader_test.dataset), epoch_acc))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XDzzCqhOZzEh",
        "outputId": "8327022a-df68-42cb-c1a2-c2e2c7443655"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 185/185 [02:13<00:00,  1.39it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "テストデータ1474個での正解率：0.9729\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "confusion_matrix(labels_all, preds_all)"
      ],
      "metadata": {
        "id": "jT6Qw4vVLB3P",
        "outputId": "e13b27d5-3244-480e-81cf-308ccd032b17",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[163,   0,   1,   2,   2,   7,   0,   0,   0],\n",
              "       [  0, 183,   1,   0,   0,   0,   0,   0,   1],\n",
              "       [  0,   4, 169,   0,   0,   3,   0,   0,   1],\n",
              "       [  2,   1,   1,  85,   0,   4,   0,   1,   0],\n",
              "       [  0,   0,   0,   0, 180,   2,   0,   0,   0],\n",
              "       [  0,   0,   0,   0,   0, 159,   0,   0,   0],\n",
              "       [  0,   1,   1,   0,   0,   0, 175,   0,   0],\n",
              "       [  0,   0,   0,   1,   0,   0,   0, 161,   3],\n",
              "       [  1,   0,   0,   0,   0,   0,   0,   0, 159]])"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Attentionの可視化"
      ],
      "metadata": {
        "id": "lBy_yin5mqnW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# BertForIMDbで処理\n",
        "\n",
        "# ミニバッチの用意\n",
        "batch = next(iter(dataloader_test))\n",
        "\n",
        "# GPUが使えるならGPUにデータを送る\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "ids_for_multi_bert = []\n",
        "for i in range(4):\n",
        "  ids_for_multi_bert.append(batch[\"ids\"][i].to(device, non_blocking=True))\n",
        "labels = batch[\"label\"].to(device)  # ラベル\n",
        "\n",
        "outputs, attention_probs = net_tmp(ids_for_multi_bert, attention_show_flg=True)\n",
        "\n",
        "_, preds = torch.max(outputs, 1)  # ラベルを予測\n"
      ],
      "metadata": {
        "id": "EHr6gDHTmu7z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(attention_probs))\n",
        "print(attention_probs[0].size())"
      ],
      "metadata": {
        "id": "9s5sOzrEmuyT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "id2label = {\n",
        "    0: 'dokujo-tsushin', \n",
        "    1: 'it-life-hack', \n",
        "    2: 'smax', \n",
        "    3: 'sports-watch', \n",
        "    4: 'kaden-channel', \n",
        "    5: 'movie-enter', \n",
        "    6: 'topic-news', \n",
        "    7: 'livedoor-homme', \n",
        "    8: 'peachy'\n",
        "}"
      ],
      "metadata": {
        "id": "k_iFpBe_nJNJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# HTMLを作成する関数を実装\n",
        "\n",
        "\n",
        "def highlight(word, attn):\n",
        "    '''\n",
        "    Attentionの値が大きいと文字の背景が濃い赤になるhtmlを出力させる関数\n",
        "    '''\n",
        "\n",
        "    html_color = '#%02X%02X%02X' % (\n",
        "        255, int(255*(1 - attn)), int(255*(1 - attn)))\n",
        "    return '<span style=\"background-color: {}\"> {}</span>'.format(html_color, word)\n",
        "\n",
        "\n",
        "def mk_html(index, batch, preds, normlized_weights):\n",
        "    '''\n",
        "    HTMLデータを作成する\n",
        "    '''\n",
        "\n",
        "    # indexの結果を抽出\n",
        "    sentence = batch[\"ids\"][0][index]  # 文章\n",
        "    label = batch[\"label\"][index]  # ラベル\n",
        "    pred = preds[index]  # 予測\n",
        "\n",
        "    # ラベルと予測結果を文字に置き換え\n",
        "    label_str = id2label[label.item()]\n",
        "    pred_str = id2label[pred.item()]\n",
        "\n",
        "    # 表示用のHTMLを作成する\n",
        "    html = f\"正解ラベル：{label_str}<br>推論ラベル：{pred_str}<br><br>\"\n",
        "\n",
        "    # Self-Attentionの重みを可視化。Multi-Headが12個なので、12種類のアテンションが存在\n",
        "    for i in range(12):\n",
        "\n",
        "        # indexのAttentionを抽出と規格化\n",
        "        # 0単語目[CLS]の、i番目のMulti-Head Attentionを取り出す\n",
        "        # indexはミニバッチの何個目のデータかをしめす\n",
        "        attens = normlized_weights[index, i, 0, :]\n",
        "        attens /= attens.max()\n",
        "\n",
        "        html += '[BERTのAttentionを可視化_' + str(i+1) + ']<br>'\n",
        "        for word, attn in zip(sentence, attens):\n",
        "\n",
        "            # 単語が[SEP]の場合は文章が終わりなのでbreak\n",
        "            if tokenizer.convert_ids_to_tokens([word.numpy().tolist()])[0] == \"[SEP]\":\n",
        "                break\n",
        "\n",
        "            # 関数highlightで色をつける、関数tokenizer_bert.convert_ids_to_tokensでIDを単語に戻す\n",
        "            html += highlight(tokenizer.convert_ids_to_tokens(\n",
        "                [word.numpy().tolist()])[0], attn)\n",
        "        html += \"<br><br>\"\n",
        "\n",
        "    # 12種類のAttentionの平均を求める。最大値で規格化\n",
        "    all_attens = attens*0  # all_attensという変数を作成する\n",
        "    for i in range(12):\n",
        "        attens += normlized_weights[index, i, 0, :]\n",
        "    attens /= attens.max()\n",
        "\n",
        "    html += '[BERTのAttentionを可視化_ALL]<br>'\n",
        "    for word, attn in zip(sentence, attens):\n",
        "\n",
        "        # 単語が[SEP]の場合は文章が終わりなのでbreak\n",
        "        if tokenizer.convert_ids_to_tokens([word.numpy().tolist()])[0] == \"[SEP]\":\n",
        "            break\n",
        "\n",
        "        # 関数highlightで色をつける、関数tokenizer_bert.convert_ids_to_tokensでIDを単語に戻す\n",
        "        html += highlight(tokenizer.convert_ids_to_tokens(\n",
        "            [word.numpy().tolist()])[0], attn)\n",
        "    html += \"<br><br>\"\n",
        "\n",
        "    return html\n"
      ],
      "metadata": {
        "id": "UVdJ0Sg4mx6J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import HTML\n",
        "\n",
        "index = 2  # 出力させたいデータ\n",
        "html_output = mk_html(index, batch, preds, attention_probs)  # HTML作成\n",
        "HTML(html_output)  # HTML形式で出力\n"
      ],
      "metadata": {
        "id": "kgYZYjfkmyqS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "RZbw3QXQpMrG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}